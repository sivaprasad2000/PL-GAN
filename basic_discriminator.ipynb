{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = torchvision.datasets.MNIST('./files/', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.5,), (0.5,))\n",
    "                             ]))\n",
    "\n",
    "mnist_test = torchvision.datasets.MNIST('./files/', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.5,), (0.5,))\n",
    "                             ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(mnist_train, 32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 1024)\n",
    "        self.fc2 = nn.Linear(self.fc1.out_features, self.fc1.out_features//2)\n",
    "        self.fc3 = nn.Linear(self.fc2.out_features, self.fc2.out_features//2)\n",
    "        self.fc4 = nn.Linear(self.fc3.out_features, 11)\n",
    "    \n",
    "    # forward method\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, 0.5)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.dropout(x, 0.5)\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.dropout(x, 0.5)\n",
    "        x = F.softmax(self.fc4(x), dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = Discriminator().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# optimizer\n",
    "D_optimizer = torch.optim.Adam(D.parameters(), lr = 0.0002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(x, y) :\n",
    "    D.zero_grad()\n",
    "\n",
    "    batch_size = len(x)\n",
    "\n",
    "    # Training on real data\n",
    "    x_real, y_real = x.view(-1, 784), y.view(-1)\n",
    "    x_real, y_real = x_real.to(device), y_real.to(device)\n",
    "\n",
    "    D_output = D(x_real)\n",
    "    D_loss = criterion(D_output, y_real)\n",
    "\n",
    "    D_loss.backward()\n",
    "    D_optimizer.step()\n",
    "        \n",
    "    return  D_loss.data.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/10: loss_d: 1.7819561958312988\n",
      "2/10: loss_d: 1.6515966653823853\n",
      "3/10: loss_d: 1.6321799755096436\n",
      "4/10: loss_d: 1.622334361076355\n",
      "5/10: loss_d: 1.617701768875122\n",
      "6/10: loss_d: 1.6131260395050049\n",
      "7/10: loss_d: 1.6114306449890137\n",
      "8/10: loss_d: 1.6073827743530273\n",
      "9/10: loss_d: 1.6055384874343872\n",
      "10/10: loss_d: 1.6068254709243774\n"
     ]
    }
   ],
   "source": [
    "n_epoch = 10\n",
    "for epoch in range(1, n_epoch+1):           \n",
    "    D_losses, G_losses = [], []\n",
    "    for batch_idx, (x, y) in enumerate(train_dataloader):\n",
    "        D_losses.append(train(x, y))\n",
    "\n",
    "    print(f'{epoch}/{n_epoch}: loss_d: {torch.mean(torch.FloatTensor(D_losses))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating accuracy for each digit\n",
    "accuracy = np.zeros(10)\n",
    "correct = np.zeros(10)\n",
    "total = np.zeros(10)\n",
    "\n",
    "for x, y in mnist_test :\n",
    "    output = D(x.view(-1, 784).to(device))\n",
    "\n",
    "    if(torch.argmax(output.cpu().detach()) == y) :\n",
    "        correct[y] += 1\n",
    "    \n",
    "    total[y] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.97653061 0.98590308 0.89147287 0.90891089 0.95519348 0.92600897\n",
      " 0.95407098 0.95719844 0.89322382 0.91674926]\n"
     ]
    }
   ],
   "source": [
    "accuracy = correct/total\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cf7cf0c9a9021c2efadcb7e41e035d7cbe6c620d92b211b5ab2d65bec9167c41"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
