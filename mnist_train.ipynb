{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lTqyQjCwtn0E"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "64ZBH_Dxtn0M"
      },
      "outputs": [],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "anh6TygHtn0N"
      },
      "outputs": [],
      "source": [
        "mnist_train = torchvision.datasets.MNIST('./files/', train=True, download=True,\n",
        "                             transform=torchvision.transforms.Compose([\n",
        "                               torchvision.transforms.ToTensor(),\n",
        "                               torchvision.transforms.Normalize(\n",
        "                                 (0.5,), (0.5,))\n",
        "                             ]))\n",
        "\n",
        "mnist_test = torchvision.datasets.MNIST('./files/', train=False, download=True,\n",
        "                             transform=torchvision.transforms.Compose([\n",
        "                               torchvision.transforms.ToTensor(),\n",
        "                               torchvision.transforms.Normalize(\n",
        "                                 (0.5,), (0.5,))\n",
        "                             ]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbkMaRu-tn0P"
      },
      "source": [
        "### Generating artificially partial labelled dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1sw_9eU6tn0Q"
      },
      "outputs": [],
      "source": [
        "def generate_partial_labelled(dataset, r, p) :\n",
        "\n",
        "    # List to store the inputs in numpy array format\n",
        "    x = []\n",
        "\n",
        "    # List to store the outputs in numpy array format\n",
        "    y = []\n",
        "\n",
        "    for i in range(len(dataset)) :\n",
        "\n",
        "        original_label = dataset[i][1]\n",
        "\n",
        "        labels = []\n",
        "        labels.append(original_label)\n",
        "\n",
        "        if np.random.rand() <= p :\n",
        "            for j in range(r) :\n",
        "                # Find a label other than the original one and append it\n",
        "                new_label = np.random.randint(0, 10)\n",
        "                while new_label in labels :\n",
        "                    new_label = np.random.randint(0, 10)\n",
        "                \n",
        "                labels.append(new_label)\n",
        "        \n",
        "        x.append(dataset[i][0].detach().numpy().reshape(28, 28))\n",
        "\n",
        "        # One hot encoding the labels before appending to the y list\n",
        "        one_hot = np.zeros(10, dtype='float32')\n",
        "\n",
        "        for label in labels :\n",
        "            one_hot[label] = 1\n",
        "\n",
        "        # Regularization\n",
        "        one_hot = one_hot/sum(one_hot)\n",
        "\n",
        "        y.append(one_hot)\n",
        "\n",
        "    return np.array(x), np.array(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "cStWl0QLtn0R"
      },
      "outputs": [],
      "source": [
        "# Creating custom dataset and dataloader\n",
        "class mnist_partial_dataset(Dataset) :\n",
        "    def __init__(self, dataset, r, p) :\n",
        "        self.x, self.y = generate_partial_labelled(dataset, r, p)\n",
        "        self.length = len(self.x)\n",
        "\n",
        "\n",
        "    def __getitem__(self, index) :\n",
        "        return self.x[index], self.y[index]\n",
        "\n",
        "    def __len__(self) :\n",
        "        return self.length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Pu7WqM3ptn0U"
      },
      "outputs": [],
      "source": [
        "train_dataset = mnist_partial_dataset(mnist_train, 1, 0.2)\n",
        "train_dataloader = DataLoader(train_dataset, 32, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "biMfcsZKtn0V"
      },
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()       \n",
        "        self.fc1 = nn.Linear(110, 256)\n",
        "        self.fc2 = nn.Linear(self.fc1.out_features, self.fc1.out_features*2)\n",
        "        self.fc3 = nn.Linear(self.fc2.out_features, self.fc2.out_features*2)\n",
        "        self.fc4 = nn.Linear(self.fc3.out_features, 784)\n",
        "    \n",
        "    # forward method\n",
        "    def forward(self, x): \n",
        "        x = F.leaky_relu(self.fc1(x), 0.2)\n",
        "        x = F.leaky_relu(self.fc2(x), 0.2)\n",
        "        x = F.leaky_relu(self.fc3(x), 0.2)\n",
        "        return torch.tanh(self.fc4(x))\n",
        "    \n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.fc1 = nn.Linear(784, 1024)\n",
        "        self.fc2 = nn.Linear(self.fc1.out_features, self.fc1.out_features//2)\n",
        "        self.fc3 = nn.Linear(self.fc2.out_features, self.fc2.out_features//2)\n",
        "        self.fc4 = nn.Linear(self.fc3.out_features, 11)\n",
        "    \n",
        "    # forward method\n",
        "    def forward(self, x):\n",
        "        x = F.leaky_relu(self.fc1(x), 0.2)\n",
        "        x = F.dropout(x, 0.5)\n",
        "        x = F.leaky_relu(self.fc2(x), 0.2)\n",
        "        x = F.dropout(x, 0.5)\n",
        "        x = F.leaky_relu(self.fc3(x), 0.2)\n",
        "        x = F.dropout(x, 0.5)\n",
        "        x = F.leaky_relu(self.fc4(x), 0.2)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "KYsLAW2Stn0W"
      },
      "outputs": [],
      "source": [
        "D = Discriminator().to(device)\n",
        "G = Generator().to(device)\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# optimizer\n",
        "D_optimizer = torch.optim.Adam(D.parameters(), lr = 0.0002)\n",
        "G_optimizer = torch.optim.Adam(G.parameters(), lr = 0.0002)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "8GbDKUfqtn0Y"
      },
      "outputs": [],
      "source": [
        "def train_D(x, y) :\n",
        "    D.zero_grad()\n",
        "\n",
        "    batch_size = len(x)\n",
        "\n",
        "    # Training on real data\n",
        "    x_real, y_real = x.view(-1, 784), torch.concat((y, torch.zeros(batch_size, 1)), 1)\n",
        "    x_real, y_real = x_real.to(device), y_real.to(device)\n",
        "\n",
        "    D_output = D(x_real)\n",
        "    D_real_loss = criterion(D_output, y_real)\n",
        "    D_real_score = D_output\n",
        "\n",
        "    # Training of fake data\n",
        "    z = torch.concat((torch.randn(batch_size, 100), y), 1).to(device)\n",
        "\n",
        "    x_fake = G(z)\n",
        "    y_fake = torch.concat((torch.zeros(batch_size, 10), torch.ones(batch_size, 1)), 1)\n",
        "    y_fake = y_fake.to(device)\n",
        "\n",
        "    D_output = D(x_fake)\n",
        "    D_fake_loss = criterion(D_output, y_fake)\n",
        "    D_fake_score = D_output\n",
        "\n",
        "    # gradient backprop & optimize ONLY D's parameters\n",
        "    D_loss = D_real_loss + D_fake_loss\n",
        "    D_loss.backward()\n",
        "    D_optimizer.step()\n",
        "        \n",
        "    return  D_loss.data.item()\n",
        "\n",
        "\n",
        "def train_G(x, y) :\n",
        "    G.zero_grad()\n",
        "\n",
        "    batch_size = len(x)\n",
        "\n",
        "    z = torch.concat((torch.randn(batch_size, 100), y), 1).to(device)\n",
        "    y_real = torch.concat((y, torch.zeros(batch_size, 1)), 1).to(device)\n",
        "\n",
        "    G_output = G(z)\n",
        "\n",
        "    D_output = D(G_output)\n",
        "    G_loss = criterion(D_output, y_real)\n",
        "\n",
        "    # gradient backprop & optimize ONLY G's parameters\n",
        "    G_loss.backward()\n",
        "    G_optimizer.step()\n",
        "        \n",
        "    return G_loss.data.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "PfdHlX15tn0Z"
      },
      "outputs": [
        {
          "ename": "IndexError",
          "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\sivap\\Projects\\Deep Learning Theory and Practices\\Project\\mnist_train.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sivap/Projects/Deep%20Learning%20Theory%20and%20Practices/Project/mnist_train.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m D_losses, G_losses \u001b[39m=\u001b[39m [], []\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sivap/Projects/Deep%20Learning%20Theory%20and%20Practices/Project/mnist_train.ipynb#X13sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch_idx, (x, y) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_dataloader):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/sivap/Projects/Deep%20Learning%20Theory%20and%20Practices/Project/mnist_train.ipynb#X13sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     G_losses\u001b[39m.\u001b[39mappend(train_G(x, y))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sivap/Projects/Deep%20Learning%20Theory%20and%20Practices/Project/mnist_train.ipynb#X13sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     D_losses\u001b[39m.\u001b[39mappend(train_D(x, y))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sivap/Projects/Deep%20Learning%20Theory%20and%20Practices/Project/mnist_train.ipynb#X13sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mn_epoch\u001b[39m}\u001b[39;00m\u001b[39m: loss_d: \u001b[39m\u001b[39m{\u001b[39;00mtorch\u001b[39m.\u001b[39mmean(torch\u001b[39m.\u001b[39mFloatTensor(D_losses))\u001b[39m}\u001b[39;00m\u001b[39m, loss_g: \u001b[39m\u001b[39m{\u001b[39;00mtorch\u001b[39m.\u001b[39mmean(torch\u001b[39m.\u001b[39mFloatTensor(G_losses))\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
            "\u001b[1;32mc:\\Users\\sivap\\Projects\\Deep Learning Theory and Practices\\Project\\mnist_train.ipynb Cell 11\u001b[0m in \u001b[0;36mtrain_G\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/sivap/Projects/Deep%20Learning%20Theory%20and%20Practices/Project/mnist_train.ipynb#X13sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m batch_size \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/sivap/Projects/Deep%20Learning%20Theory%20and%20Practices/Project/mnist_train.ipynb#X13sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m z \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mconcat((torch\u001b[39m.\u001b[39mrandn(batch_size, \u001b[39m100\u001b[39m), y\u001b[39m.\u001b[39mreshape(batch_size, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)), \u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/sivap/Projects/Deep%20Learning%20Theory%20and%20Practices/Project/mnist_train.ipynb#X13sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m y_real \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mconcat((y, torch\u001b[39m.\u001b[39;49mzeros(batch_size, \u001b[39m1\u001b[39;49m)), \u001b[39m1\u001b[39;49m)\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/sivap/Projects/Deep%20Learning%20Theory%20and%20Practices/Project/mnist_train.ipynb#X13sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m G_output \u001b[39m=\u001b[39m G(z)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/sivap/Projects/Deep%20Learning%20Theory%20and%20Practices/Project/mnist_train.ipynb#X13sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m D_output \u001b[39m=\u001b[39m D(G_output)\n",
            "\u001b[1;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
          ]
        }
      ],
      "source": [
        "n_epoch = 10\n",
        "for epoch in range(1, n_epoch+1):           \n",
        "    D_losses, G_losses = [], []\n",
        "    for batch_idx, (x, y) in enumerate(train_dataloader):\n",
        "        G_losses.append(train_G(x, y))\n",
        "        D_losses.append(train_D(x, y))\n",
        "\n",
        "    print(f'{epoch}/{n_epoch}: loss_d: {torch.mean(torch.FloatTensor(D_losses))}, loss_g: {torch.mean(torch.FloatTensor(G_losses))}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "UQd-wa4etn0a",
        "outputId": "2cb4c080-bc59-4b2d-8474-91c3f140a250"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[-0.0310, -0.0195, -0.0140,  0.0648, -0.0123, -0.0203, -0.0070, -0.0209,\n",
            "         -0.0028, -0.0045,  0.9299]], device='cuda:0')\n",
            "tensor(1.4855)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "image_grid = []\n",
        "\n",
        "with torch.no_grad() :\n",
        "    for num in range(10) :\n",
        "        for i in range(10) :\n",
        "            y = torch.zeros(1,10)\n",
        "            y[0][num] = 1\n",
        "            z = torch.concat((torch.randn(1, 100), y), 1).to(device)\n",
        "\n",
        "            output = G(z)\n",
        "\n",
        "            output = output.cpu().detach().numpy()\n",
        "            output = output.reshape(28, 28)\n",
        "\n",
        "            image_grid.append(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.save(D.state_dict(), './models/mnist_r_value_1_p_value_0.7.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "cf7cf0c9a9021c2efadcb7e41e035d7cbe6c620d92b211b5ab2d65bec9167c41"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
