{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lTqyQjCwtn0E"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "64ZBH_Dxtn0M"
      },
      "outputs": [],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "anh6TygHtn0N"
      },
      "outputs": [],
      "source": [
        "cifar_train = torchvision.datasets.CIFAR10('./files/', train=True, download=True,\n",
        "                             transform=torchvision.transforms.Compose([\n",
        "                               torchvision.transforms.ToTensor(),\n",
        "                               torchvision.transforms.Normalize(\n",
        "                                 (0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "                             ]))\n",
        "\n",
        "cifar_test = torchvision.datasets.CIFAR10('./files/', train=False, download=True,\n",
        "                             transform=torchvision.transforms.Compose([\n",
        "                               torchvision.transforms.ToTensor(),\n",
        "                               torchvision.transforms.Normalize(\n",
        "                                 (0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "                             ]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbkMaRu-tn0P"
      },
      "source": [
        "### Generating artificially partial labelled dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1sw_9eU6tn0Q"
      },
      "outputs": [],
      "source": [
        "def generate_partial_labelled(dataset, r, p) :\n",
        "\n",
        "    # List to store the inputs in numpy array format\n",
        "    x = []\n",
        "\n",
        "    # List to store the outputs in numpy array format\n",
        "    y = []\n",
        "\n",
        "    for i in range(len(dataset)) :\n",
        "\n",
        "        original_label = dataset[i][1]\n",
        "\n",
        "        labels = []\n",
        "        labels.append(original_label)\n",
        "\n",
        "        if np.random.rand() <= p :\n",
        "            for j in range(r) :\n",
        "                # Find a label other than the original one and append it\n",
        "                new_label = np.random.randint(0, 10)\n",
        "                while new_label in labels :\n",
        "                    new_label = np.random.randint(0, 10)\n",
        "                \n",
        "                labels.append(new_label)\n",
        "        \n",
        "        x.append(dataset[i][0].detach().numpy().reshape(3, 32, 32))\n",
        "\n",
        "        # One hot encoding the labels before appending to the y list\n",
        "        one_hot = np.zeros(10, dtype='float32')\n",
        "\n",
        "        for label in labels :\n",
        "            one_hot[label] = 1\n",
        "\n",
        "        # Regularization\n",
        "        one_hot = np.sum(one_hot)\n",
        "\n",
        "        y.append(one_hot)\n",
        "\n",
        "    return np.array(x), np.array(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cStWl0QLtn0R"
      },
      "outputs": [],
      "source": [
        "# Creating custom dataset and dataloader\n",
        "class cifar10_partial_dataset(Dataset) :\n",
        "    def __init__(self, dataset, r, p) :\n",
        "        self.x, self.y = generate_partial_labelled(dataset, r, p)\n",
        "        self.length = len(self.x)\n",
        "\n",
        "\n",
        "    def __getitem__(self, index) :\n",
        "        return self.x[index], self.y[index]\n",
        "\n",
        "    def __len__(self) :\n",
        "        return self.length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "r = 1\n",
        "p = 0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pu7WqM3ptn0U"
      },
      "outputs": [],
      "source": [
        "train_dataset = cifar10_partial_dataset(cifar_train, r, p)\n",
        "train_dataloader = DataLoader(train_dataset, 32, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "biMfcsZKtn0V"
      },
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        \n",
        "        self.main = nn.Sequential(\n",
        "            nn.ConvTranspose2d( 110, 64 * 8, 4, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(64 * 8),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(64 * 8, 64 * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(64 * 4),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d( 64 * 4, 64 * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(64 * 2),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d( 64 * 2, 3, 4, 2, 1, bias=False),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input)\n",
        "    \n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(64, 64 * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(64 * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(64 * 2, 64 * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(64 * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(64 * 4, 11, 4, 1, 0, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KYsLAW2Stn0W"
      },
      "outputs": [],
      "source": [
        "D = Discriminator().to(device)\n",
        "G = Generator().to(device)\n",
        "\n",
        "D.apply(weights_init)\n",
        "G.apply(weights_init)\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# optimizer\n",
        "D_optimizer = torch.optim.Adam(D.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "G_optimizer = torch.optim.Adam(G.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "D_optimizer = torch.optim.Adam(D.parameters(), lr = 0.0002)\n",
        "G_optimizer = torch.optim.Adam(G.parameters(), lr = 0.0002)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8GbDKUfqtn0Y"
      },
      "outputs": [],
      "source": [
        "def train_D(x, y) :\n",
        "    D.zero_grad()\n",
        "\n",
        "    batch_size = len(x)\n",
        "\n",
        "    # Training on real data\n",
        "    x_real, y_real = x.view(-1, 3, 32, 32), torch.concat((y, torch.zeros(batch_size, 1)), 1)\n",
        "    x_real, y_real = x_real.to(device), y_real.to(device)\n",
        "\n",
        "    D_output = D(x_real).view(-1, 11)\n",
        "    D_real_loss = criterion(D_output, y_real)\n",
        "    D_real_score = D_output\n",
        "\n",
        "    # Training of fake data\n",
        "    z = torch.concat((torch.randn(batch_size, 100), y), 1).view(-1, 110, 1, 1).to(device)\n",
        "\n",
        "    x_fake = G(z)\n",
        "    y_fake = torch.concat((torch.zeros(batch_size, 10), torch.ones(batch_size, 1)), 1)\n",
        "    y_fake = y_fake.to(device)\n",
        "\n",
        "    D_output = D(x_fake).view(-1, 11)\n",
        "    D_fake_loss = criterion(D_output, y_fake)\n",
        "    D_fake_score = D_output\n",
        "\n",
        "    # gradient backprop & optimize ONLY D's parameters\n",
        "    D_loss = D_real_loss + D_fake_loss\n",
        "    D_loss.backward()\n",
        "    D_optimizer.step()\n",
        "        \n",
        "    return  D_loss.data.item()\n",
        "\n",
        "\n",
        "def train_G(x, y) :\n",
        "    G.zero_grad()\n",
        "\n",
        "    batch_size = len(x)\n",
        "\n",
        "    z = torch.concat((torch.randn(batch_size, 100), y), 1).view(-1, 110, 1, 1).to(device)\n",
        "    y_real = torch.concat((y, torch.zeros(batch_size, 1)), 1).to(device)\n",
        "\n",
        "    G_output = G(z)\n",
        "\n",
        "    D_output = D(G_output).view(-1, 11)\n",
        "    G_loss = criterion(D_output, y_real)\n",
        "\n",
        "    # gradient backprop & optimize ONLY G's parameters\n",
        "    G_loss.backward()\n",
        "    G_optimizer.step()\n",
        "        \n",
        "    return G_loss.data.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PfdHlX15tn0Z"
      },
      "outputs": [],
      "source": [
        "n_epoch = 30\n",
        "for epoch in range(1, n_epoch+1):           \n",
        "    D_losses, G_losses = [], []\n",
        "    for batch_idx, (x, y) in enumerate(train_dataloader):\n",
        "        G_losses.append(train_G(x, y))\n",
        "        D_losses.append(train_D(x, y))\n",
        "\n",
        "    print(f'{epoch}/{n_epoch}: loss_d: {torch.mean(torch.FloatTensor(D_losses))}, loss_g: {torch.mean(torch.FloatTensor(G_losses))}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "UQd-wa4etn0a",
        "outputId": "2cb4c080-bc59-4b2d-8474-91c3f140a250"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad() :\n",
        "    y = torch.zeros(1,10)\n",
        "    y[0][7] = 1\n",
        "    z = torch.concat((torch.randn(1, 100), y), 1).view(-1, 110, 1, 1).to(device)\n",
        "\n",
        "    output = G(z)\n",
        "    expected = torch.zeros(1, 11)\n",
        "    expected[0][2] = 1\n",
        "\n",
        "    # print(D(output))\n",
        "    # print(torch.sum((expected-D(output).cpu().detach())**2))\n",
        "\n",
        "    output = output.cpu().detach().numpy()\n",
        "    output = output.reshape(3, 32, 32)\n",
        "\n",
        "    reshapedImg = np.zeros((32, 32, 3), dtype='float32')\n",
        "\n",
        "    reshapedImg[:, :, 0] = output[0, :, :]\n",
        "    reshapedImg[:, :, 1] = output[1, :, :]\n",
        "    reshapedImg[:, :, 2] = output[2, :, :]\n",
        "\n",
        "    plt.imshow(reshapedImg)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.save(D.state_dict(), f'./models/cifar10_disc_r_value_1_p_value_{p}.pt')\n",
        "torch.save(G.state_dict(), f'./models/cifar10_gen_r_value_1_p_value_{p}.pt')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "cf7cf0c9a9021c2efadcb7e41e035d7cbe6c620d92b211b5ab2d65bec9167c41"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
